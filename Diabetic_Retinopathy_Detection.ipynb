{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ahmednasser1601/diabetic-retinopathy-detection?scriptVersionId=106728062\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# ***Name: Ahmed Nasser Ahmed Hassan***\n> **CodeClause |> *Sep/2022***\n>> **Data Science Intern |> *CC-OL-911***\n>>> **Task2 >> *Diabetic Retinopathy Detection***\n---","metadata":{}},{"cell_type":"markdown","source":"### ***About the Data***\n*These images consist of gaussian filtered retina scan images to detect diabetic retinopathy, and the original dataset is available at [APTOS 2019 Blindness Detection](https://www.kaggle.com/c/aptos2019-blindness-detection/overview). These images are resized into 224x224 pixels so that they can be readily used with many pre-trained deep learning models.*\n\n> |> *There are five image directories:*\n* *0 -> No_DR*\n* *1 -> Mild*\n* *2 -> Moderate*\n* *3 -> Severe*\n* *4 -> Proliferate_DR*","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import sys\nimport os.path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom time import perf_counter\nfrom pathlib import Path\nfrom IPython.display import Image, display, Markdown\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\n\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:27:08.277882Z","iopub.execute_input":"2022-09-28T02:27:08.278517Z","iopub.status.idle":"2022-09-28T02:27:08.286208Z","shell.execute_reply.started":"2022-09-28T02:27:08.278477Z","shell.execute_reply":"2022-09-28T02:27:08.28508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def printmd(string):\n    display(Markdown(string))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:14.837324Z","iopub.execute_input":"2022-09-28T00:37:14.838016Z","iopub.status.idle":"2022-09-28T00:37:14.842933Z","shell.execute_reply.started":"2022-09-28T00:37:14.837963Z","shell.execute_reply":"2022-09-28T00:37:14.841854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imageDir = Path('../input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images')\n\nfilepaths = list(imageDir.glob(r'**/*.png'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:19.107493Z","iopub.execute_input":"2022-09-28T00:37:19.107907Z","iopub.status.idle":"2022-09-28T00:37:19.537051Z","shell.execute_reply.started":"2022-09-28T00:37:19.107872Z","shell.execute_reply":"2022-09-28T00:37:19.53603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\nimage_df = pd.concat([filepaths, labels], axis=1)\nimage_df = image_df.sample(frac=1).reset_index(drop = True)\n\nimage_df","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:22.281338Z","iopub.execute_input":"2022-09-28T00:37:22.281712Z","iopub.status.idle":"2022-09-28T00:37:22.310574Z","shell.execute_reply.started":"2022-09-28T00:37:22.281681Z","shell.execute_reply":"2022-09-28T00:37:22.309683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***Visualization***","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 10), subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(image_df.Filepath[i]))\n    ax.set_title(image_df.Label[i])\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:26.332487Z","iopub.execute_input":"2022-09-28T00:37:26.33286Z","iopub.status.idle":"2022-09-28T00:37:27.412043Z","shell.execute_reply.started":"2022-09-28T00:37:26.33283Z","shell.execute_reply":"2022-09-28T00:37:27.411084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vc = image_df['Label'].value_counts()\nplt.figure(figsize=(10, 5))\nsns.barplot(x=vc.index, y=vc, palette=\"rocket\")\nplt.title(\"No. of pictures in each category\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:32.045526Z","iopub.execute_input":"2022-09-28T00:37:32.045901Z","iopub.status.idle":"2022-09-28T00:37:32.25094Z","shell.execute_reply.started":"2022-09-28T00:37:32.045869Z","shell.execute_reply":"2022-09-28T00:37:32.249933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***2. Load the Images with a generator***<a class=\"anchor\" id=\"2\"></a>","metadata":{}},{"cell_type":"code","source":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.1\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:35.480977Z","iopub.execute_input":"2022-09-28T00:37:35.481546Z","iopub.status.idle":"2022-09-28T00:37:35.738761Z","shell.execute_reply.started":"2022-09-28T00:37:35.481513Z","shell.execute_reply":"2022-09-28T00:37:35.737674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainImg():\n    return train_generator.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=(224, 224),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=True,\n        seed=0,\n        subset='training',\n        rotation_range=30,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\"\n    )","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:38.997747Z","iopub.execute_input":"2022-09-28T00:37:38.998135Z","iopub.status.idle":"2022-09-28T00:37:39.005823Z","shell.execute_reply.started":"2022-09-28T00:37:38.998104Z","shell.execute_reply":"2022-09-28T00:37:39.004227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainGen():\n    return train_generator.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=(224, 224),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=True,\n        seed=0,\n        subset='validation',\n        rotation_range=30,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\"\n    )","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:41.987792Z","iopub.execute_input":"2022-09-28T00:37:41.988184Z","iopub.status.idle":"2022-09-28T00:37:41.994162Z","shell.execute_reply.started":"2022-09-28T00:37:41.98815Z","shell.execute_reply":"2022-09-28T00:37:41.993141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def testGen():\n    return test_generator.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=(224, 224),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=False\n    )","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:46.018164Z","iopub.execute_input":"2022-09-28T00:37:46.018533Z","iopub.status.idle":"2022-09-28T00:37:46.024591Z","shell.execute_reply.started":"2022-09-28T00:37:46.018504Z","shell.execute_reply":"2022-09-28T00:37:46.023561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createGen():\n    train_images = trainImg()\n    val_images = trainGen()\n    test_images = testGen()\n    return train_generator, test_generator, train_images, val_images, test_images","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:49.443039Z","iopub.execute_input":"2022-09-28T00:37:49.443648Z","iopub.status.idle":"2022-09-28T00:37:49.448816Z","shell.execute_reply.started":"2022-09-28T00:37:49.443612Z","shell.execute_reply":"2022-09-28T00:37:49.447654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***3. Test 27 canned architectures with pretrained weights***<a class=\"anchor\" id=\"3\"></a>","metadata":{}},{"cell_type":"code","source":"def getModel(model):\n    kwargs = {\n        'input_shape':(224, 224, 3),\n        'include_top':False,\n        'weights':'imagenet',\n        'pooling':'avg'\n    }\n    \n    pretrained_model = model(**kwargs)\n    pretrained_model.trainable = False\n    \n    inputs = pretrained_model.input\n\n    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n\n    outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:37:54.736057Z","iopub.execute_input":"2022-09-28T00:37:54.736418Z","iopub.status.idle":"2022-09-28T00:37:54.744235Z","shell.execute_reply.started":"2022-09-28T00:37:54.736389Z","shell.execute_reply":"2022-09-28T00:37:54.742978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(image_df, train_size=0.9, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:38:02.23075Z","iopub.execute_input":"2022-09-28T00:38:02.231139Z","iopub.status.idle":"2022-09-28T00:38:02.238535Z","shell.execute_reply.started":"2022-09-28T00:38:02.231107Z","shell.execute_reply":"2022-09-28T00:38:02.237408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n    \"DenseNet169\": {\"model\":tf.keras.applications.DenseNet169, \"perf\":0},\n    \"DenseNet201\": {\"model\":tf.keras.applications.DenseNet201, \"perf\":0},\n    \"EfficientNetB0\": {\"model\":tf.keras.applications.EfficientNetB0, \"perf\":0},\n    \"EfficientNetB1\": {\"model\":tf.keras.applications.EfficientNetB1, \"perf\":0},\n    \"EfficientNetB2\": {\"model\":tf.keras.applications.EfficientNetB2, \"perf\":0},\n    \"EfficientNetB3\": {\"model\":tf.keras.applications.EfficientNetB3, \"perf\":0},\n    \"EfficientNetB4\": {\"model\":tf.keras.applications.EfficientNetB4, \"perf\":0},\n    \"EfficientNetB5\": {\"model\":tf.keras.applications.EfficientNetB4, \"perf\":0},\n    \"EfficientNetB6\": {\"model\":tf.keras.applications.EfficientNetB4, \"perf\":0},\n    \"EfficientNetB7\": {\"model\":tf.keras.applications.EfficientNetB4, \"perf\":0},\n    \"InceptionResNetV2\": {\"model\":tf.keras.applications.InceptionResNetV2, \"perf\":0},\n    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n    \"MobileNet\": {\"model\":tf.keras.applications.MobileNet, \"perf\":0},\n    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n    \"MobileNetV3Large\": {\"model\":tf.keras.applications.MobileNetV3Large, \"perf\":0},\n    \"MobileNetV3Small\": {\"model\":tf.keras.applications.MobileNetV3Small, \"perf\":0},\n    \"NASNetMobile\": {\"model\":tf.keras.applications.NASNetMobile, \"perf\":0},\n    \"ResNet101\": {\"model\":tf.keras.applications.ResNet101, \"perf\":0},\n    \"ResNet101V2\": {\"model\":tf.keras.applications.ResNet101V2, \"perf\":0},\n    \"ResNet152\": {\"model\":tf.keras.applications.ResNet152, \"perf\":0},\n    \"ResNet152V2\": {\"model\":tf.keras.applications.ResNet152V2, \"perf\":0},\n    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n    \"ResNet50V2\": {\"model\":tf.keras.applications.ResNet50V2, \"perf\":0},\n    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0},\n    \"Xception\": {\"model\":tf.keras.applications.Xception, \"perf\":0}\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-28T00:38:05.74414Z","iopub.execute_input":"2022-09-28T00:38:05.744577Z","iopub.status.idle":"2022-09-28T00:38:05.756567Z","shell.execute_reply.started":"2022-09-28T00:38:05.744543Z","shell.execute_reply":"2022-09-28T00:38:05.755448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator, test_generator, train_images, val_images, test_images = createGen()\n\nfor name, model in models.items():\n    m = getModel(model['model'])\n    models[name]['model'] = m\n    \n    start = perf_counter()\n    history = m.fit(train_images, validation_data=val_images, epochs=10)\n    \n    duration = round((perf_counter() - start), 2)\n    models[name]['perf'] = duration\n    print(f\"{name:20} -> trained in -> {duration} Sec\")\n    \n    valAcc = history.history['val_accuracy']\n    models[name]['val_acc'] = [round(v, 4) for v in valAcc]\n    \n    trainAcc = history.history['accuracy']\n    models[name]['train_accuracy'] = [round(v, 4) for v in trainAcc]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-09-28T00:38:11.28567Z","iopub.execute_input":"2022-09-28T00:38:11.286058Z","iopub.status.idle":"2022-09-28T01:41:45.982796Z","shell.execute_reply.started":"2022-09-28T00:38:11.286022Z","shell.execute_reply":"2022-09-28T01:41:45.981618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelsResult = []\n\nfor name, v in models.items():\n    modelsResult.append(\n        [\n            name,\n            models[name]['train_accuracy'][-1],\n            models[name]['val_acc'][-1],\n            models[name]['perf']\n        ]\n    )\n    \ndfResults = pd.DataFrame(\n    modelsResult,\n    columns = [\n        'Model',\n        'train_accuracy',\n        'val_accuracy',\n        'Training time (sec)'\n    ]\n)\n\ndfResults.sort_values(by='val_accuracy', ascending=False, inplace=True)\ndfResults.reset_index(inplace=True, drop=True)\ndfResults","metadata":{"execution":{"iopub.status.busy":"2022-09-28T01:52:26.841059Z","iopub.execute_input":"2022-09-28T01:52:26.841785Z","iopub.status.idle":"2022-09-28T01:52:26.860826Z","shell.execute_reply.started":"2022-09-28T01:52:26.841748Z","shell.execute_reply":"2022-09-28T01:52:26.859792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nplt.title('Accuracy of Training Set (after 10 epochs)', fontsize=12)\nsns.barplot(x='model', y='train_accuracy', data=df_results)\nplt.ylim(0, 1)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T01:58:37.657935Z","iopub.execute_input":"2022-09-28T01:58:37.658992Z","iopub.status.idle":"2022-09-28T01:58:38.04489Z","shell.execute_reply.started":"2022-09-28T01:58:37.658943Z","shell.execute_reply":"2022-09-28T01:58:38.043936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 10))\nplt.title('Accuracy of Validation Set (after 10 epoch)', fontsize = 15)\nsns.barplot(x = 'model', y = 'val_accuracy', data = df_results)\nplt.ylim(0,1)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:24:43.233543Z","iopub.execute_input":"2022-09-28T02:24:43.233922Z","iopub.status.idle":"2022-09-28T02:24:43.627863Z","shell.execute_reply.started":"2022-09-28T02:24:43.233891Z","shell.execute_reply":"2022-09-28T02:24:43.626933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.barplot(x='model', y='Training time (sec)', data=df_results)\nplt.title('Training time for each model in (Sec)', fontsize=12)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:24:59.099861Z","iopub.execute_input":"2022-09-28T02:24:59.100575Z","iopub.status.idle":"2022-09-28T02:24:59.495881Z","shell.execute_reply.started":"2022-09-28T02:24:59.100536Z","shell.execute_reply":"2022-09-28T02:24:59.494907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***4. Train the model MobileNetV2***<a class=\"anchor\" id=\"4\"></a>","metadata":{}},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:06:02.108095Z","iopub.execute_input":"2022-09-28T02:06:02.108989Z","iopub.status.idle":"2022-09-28T02:06:03.086469Z","shell.execute_reply.started":"2022-09-28T02:06:02.108942Z","shell.execute_reply":"2022-09-28T02:06:03.085399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    batch_size = 32,\n    epochs=10,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=2,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-09-28T02:09:44.804361Z","iopub.execute_input":"2022-09-28T02:09:44.804843Z","iopub.status.idle":"2022-09-28T02:11:17.790444Z","shell.execute_reply.started":"2022-09-28T02:09:44.804802Z","shell.execute_reply":"2022-09-28T02:11:17.789104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\nplt.title(\"Accuracy VS val_accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:16:50.435779Z","iopub.execute_input":"2022-09-28T02:16:50.436193Z","iopub.status.idle":"2022-09-28T02:16:50.642988Z","shell.execute_reply.started":"2022-09-28T02:16:50.436159Z","shell.execute_reply":"2022-09-28T02:16:50.641938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss VS val_loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:16:55.876776Z","iopub.execute_input":"2022-09-28T02:16:55.877166Z","iopub.status.idle":"2022-09-28T02:16:56.097961Z","shell.execute_reply.started":"2022-09-28T02:16:55.877134Z","shell.execute_reply":"2022-09-28T02:16:56.096921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***5. Visualize the result***<a class=\"anchor\" id=\"5\"></a>","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:17:28.961059Z","iopub.execute_input":"2022-09-28T02:17:28.962326Z","iopub.status.idle":"2022-09-28T02:17:32.539891Z","shell.execute_reply.started":"2022-09-28T02:17:28.96227Z","shell.execute_reply":"2022-09-28T02:17:32.538833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printmd(\"### Test Loss |> {:.5f}\".format(results[0]))\nprintmd(\"### Accuracy on test set |> {:.2f}%\".format(results[1] *100))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:20:45.240233Z","iopub.execute_input":"2022-09-28T02:20:45.240596Z","iopub.status.idle":"2022-09-28T02:20:45.24943Z","shell.execute_reply.started":"2022-09-28T02:20:45.240567Z","shell.execute_reply":"2022-09-28T02:20:45.248261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\nlabels = (train_images.class_indices)\nlabels = dict((v, k) for k, v in labels.items())\n\npred = [labels[k] for k in pred]\n\nprint(f'The first 10 predictions: {pred[:10]}')","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:25:51.467498Z","iopub.execute_input":"2022-09-28T02:25:51.467872Z","iopub.status.idle":"2022-09-28T02:25:52.759968Z","shell.execute_reply.started":"2022-09-28T02:25:51.467841Z","shell.execute_reply":"2022-09-28T02:25:52.758933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:26:22.848481Z","iopub.execute_input":"2022-09-28T02:26:22.848858Z","iopub.status.idle":"2022-09-28T02:26:22.865786Z","shell.execute_reply.started":"2022-09-28T02:26:22.848826Z","shell.execute_reply":"2022-09-28T02:26:22.864898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (15, 10))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Normalized Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:35:29.545019Z","iopub.execute_input":"2022-09-28T02:35:29.545716Z","iopub.status.idle":"2022-09-28T02:35:29.855336Z","shell.execute_reply.started":"2022-09-28T02:35:29.545681Z","shell.execute_reply":"2022-09-28T02:35:29.853995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(\n    nrows=3, ncols=3,\n    figsize=(15, 15),\n    subplot_kw={\n        'xticks': [],\n        'yticks': []\n    }\n)\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:29:54.140501Z","iopub.execute_input":"2022-09-28T02:29:54.140888Z","iopub.status.idle":"2022-09-28T02:29:55.439676Z","shell.execute_reply.started":"2022-09-28T02:29:54.140856Z","shell.execute_reply":"2022-09-28T02:29:55.438829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***6. Class activation heatmap for image classification***<a class=\"anchor\" id=\"6\"></a>\n## Grad-CAM class activation visualization","metadata":{}},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = tf.keras.preprocessing.image.img_to_array(img)\n    array = np.expand_dims(array, axis=0)\n    return array","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:33:24.727061Z","iopub.execute_input":"2022-09-28T02:33:24.727459Z","iopub.status.idle":"2022-09-28T02:33:24.733417Z","shell.execute_reply.started":"2022-09-28T02:33:24.727425Z","shell.execute_reply":"2022-09-28T02:33:24.732154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    \n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None: pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    \n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    \n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:40:26.225359Z","iopub.execute_input":"2022-09-28T02:40:26.225724Z","iopub.status.idle":"2022-09-28T02:40:26.233874Z","shell.execute_reply.started":"2022-09-28T02:40:26.225695Z","shell.execute_reply":"2022-09-28T02:40:26.232855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    img = tf.keras.preprocessing.image.load_img(img_path)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n\n    heatmap = np.uint8(255 * heatmap)\n\n    jet = cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n    superimposed_img.save(cam_path)\n    return cam_path","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:43:52.779107Z","iopub.execute_input":"2022-09-28T02:43:52.779481Z","iopub.status.idle":"2022-09-28T02:43:52.788129Z","shell.execute_reply.started":"2022-09-28T02:43:52.779451Z","shell.execute_reply":"2022-09-28T02:43:52.787045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\ndecode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n\nlast_conv_layer_name = \"Conv_1\"\nimg_size = (224,224)\n\nmodel.layers[-1].activation = None","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:44:26.492149Z","iopub.execute_input":"2022-09-28T02:44:26.49252Z","iopub.status.idle":"2022-09-28T02:44:26.498653Z","shell.execute_reply.started":"2022-09-28T02:44:26.492489Z","shell.execute_reply":"2022-09-28T02:44:26.497497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(\n    nrows=3,\n    ncols=5,\n    figsize=(15, 10),\n    subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    img_path = test_df.Filepath.iloc[i]\n    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n    cam_path = save_and_display_gradcam(img_path, heatmap)\n    ax.imshow(plt.imread(cam_path))\n    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:45:36.266923Z","iopub.execute_input":"2022-09-28T02:45:36.267983Z","iopub.status.idle":"2022-09-28T02:45:39.471917Z","shell.execute_reply.started":"2022-09-28T02:45:36.267933Z","shell.execute_reply":"2022-09-28T02:45:39.47103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***7. Using a two-class model (DR and No_DR)***<a class=\"anchor\" id=\"7\"></a>\nMap the labels to have only \"No_DR\" and \"DR\"","metadata":{}},{"cell_type":"code","source":"image_df_red = image_df.copy()\nimage_df_red['Label'] = image_df_red['Label'].apply(lambda x: x if x == 'No_DR' else 'DR')\nimage_df_red","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:47:57.110259Z","iopub.execute_input":"2022-09-28T02:47:57.1114Z","iopub.status.idle":"2022-09-28T02:47:57.126864Z","shell.execute_reply.started":"2022-09-28T02:47:57.111356Z","shell.execute_reply":"2022-09-28T02:47:57.125575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vc = image_df_red['Label'].value_counts()\nplt.figure(figsize=(10, 5))\nsns.barplot(x=vc.index, y=vc, palette=\"rocket\")\nplt.title(\"Number of pictures of each category\", fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:51:41.937206Z","iopub.execute_input":"2022-09-28T02:51:41.937828Z","iopub.status.idle":"2022-09-28T02:51:42.113976Z","shell.execute_reply.started":"2022-09-28T02:51:41.937793Z","shell.execute_reply":"2022-09-28T02:51:42.112932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(image_df_red, train_size=0.9, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T02:53:28.000822Z","iopub.execute_input":"2022-09-28T02:53:28.001229Z","iopub.status.idle":"2022-09-28T02:53:28.010812Z","shell.execute_reply.started":"2022-09-28T02:53:28.001197Z","shell.execute_reply":"2022-09-28T02:53:28.009777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator,test_generator,train_images,val_images,test_images=createGen()\n\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\npretrained_model.trainable = False\n\ninputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    batch_size = 32,\n    epochs=10,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-09-28T02:54:59.542631Z","iopub.execute_input":"2022-09-28T02:54:59.543045Z","iopub.status.idle":"2022-09-28T02:56:17.989315Z","shell.execute_reply.started":"2022-09-28T02:54:59.54299Z","shell.execute_reply":"2022-09-28T02:56:17.988282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\nplt.title(\"Accuracy VS val_accuracy\")\nplt.show()\n\npd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss VS val_loss\")\nplt.show()\n\nresults = model.evaluate(test_images, verbose=0)\n\nprintmd(\"## Test Loss | {:.5f}\".format(results[0]))\nprintmd(\"## Accuracy on the test set | {:.2f}%\".format(results[1] *100))\n\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\npred = [labels[k] for k in pred]\nprint(f'The first 5 predictions: {pred[:5]}')\n\ny_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T03:00:17.168623Z","iopub.execute_input":"2022-09-28T03:00:17.169051Z","iopub.status.idle":"2022-09-28T03:00:34.495915Z","shell.execute_reply.started":"2022-09-28T03:00:17.168996Z","shell.execute_reply":"2022-09-28T03:00:34.494684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (15, 10))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Normalized Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T03:01:34.20521Z","iopub.execute_input":"2022-09-28T03:01:34.205949Z","iopub.status.idle":"2022-09-28T03:01:34.455068Z","shell.execute_reply.started":"2022-09-28T03:01:34.20591Z","shell.execute_reply":"2022-09-28T03:01:34.453965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}}]}