{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMK9oxgwEXDjozNa5UQxuMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedNasser1601/Diabetic-Retinopathy-Detection/blob/Main/Diabetic_Retinopathy_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Name: Ahmed Nasser Ahmed Hassan***\n",
        "> **CodeClause |> *Sep/2022***\n",
        ">> **Data Science Intern |> *CC-OL-911***\n",
        ">>> **Task2 >> *Diabetic Retinopathy Detection***\n",
        "---"
      ],
      "metadata": {
        "id": "NuMEUcRCF7_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### |> ***Requirements***"
      ],
      "metadata": {
        "id": "rOu9M5V-gSTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> #### |> ***Import Packages***"
      ],
      "metadata": {
        "id": "r714vM0-xJPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import random\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "from subprocess import check_output\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WCS67-KXYZe8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9V7pCCZFEPfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classes_to_int(label):\n",
        "  label = label.strip()\n",
        "\n",
        "  if label==\"No DR\": return 0\n",
        "  if label==\"Mild\": return 1\n",
        "  if label==\"Moderate\": return 2\n",
        "  if label==\"Severe\": return 3\n",
        "  if label==\"Proliferative DR\": return 4\n",
        "\n",
        "  print(\"Invalid Label\", label)\n",
        "  return 5"
      ],
      "metadata": {
        "id": "o5jSZVJo92zR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_classes(i):\n",
        "  if i==0: return \"No DR\"\n",
        "  elif i==1: return \"Mild\"\n",
        "  elif i==2: return \"Moderate\"\n",
        "  elif i==3: return \"Severe\"\n",
        "  elif i==4: return \"Proliferative DR\"\n",
        "  \n",
        "  print(\"Invalid class \", i)\n",
        "  return \"Invalid Class\""
      ],
      "metadata": {
        "id": "90M-O8zB-tBI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5\n",
        "\n",
        "Height = 128\n",
        "Width = 128\n",
        "Depth = 3\n",
        "inputShape = (Height, Width, Depth)\n",
        "\n",
        "EPOCHS = 15   #epochs to train\n",
        "INIT_LR = 1e-3   #initial learning rate\n",
        "BS = 32   #batch size\n",
        "\n",
        "ImageNameDataHash = {}\n",
        "uniquePatientIDList = []"
      ],
      "metadata": {
        "id": "xkpI0YduDQN4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZV4NnjpPEX6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readTrainData(trainDir):\n",
        "  global ImageNameDataHash\n",
        "\n",
        "  images = os.listdir(trainDir)\n",
        "  print(\"Number of files in \" + trainDir + \" is \" + str(len(images)))\n",
        "\n",
        "  for imageFileName in images:\n",
        "    if (imageFileName == \"trainLabels.csv\"): continue\n",
        "\n",
        "    imageFullPath = os.path.join(os.path.sep, trainDir, imageFileName)\n",
        "    img = load_img(imageFullPath)\n",
        "\n",
        "    arr = img_to_array(img)\n",
        "    dim1 = arr.shape[0]\n",
        "    dim2 = arr.shape[1]\n",
        "    dim3 = arr.shape[2]\n",
        "\n",
        "    if (dim1<Height or dim2<Width or dim3<Depth):\n",
        "      print(\"Error image dimensions are less than expected \" + str(arr.shape))\n",
        "    \n",
        "    arr = cv2.resize(arr, (Height, Width))\n",
        "    dim1 = arr.shape[0]\n",
        "    dim2 = arr.shape[1]\n",
        "    dim3 = arr.shape[2]\n",
        "\n",
        "    if (dim1 != Height or dim2 != Width or dim3 != Depth):\n",
        "      print(\"Error after resize, image dimensions are not equal to expected \" + str(arr.shape))\n",
        "\n",
        "    #scale the raw pixel intensities to the range [0, 1] - TBD TEST\n",
        "    arr = np.array(arr, dtype=\"float\") / 255.0\n",
        "    imageFileName = imageFileName.replace('.jpeg','')\n",
        "    ImageNameDataHash[str(imageFileName)] = np.array(arr)\n",
        "  return"
      ],
      "metadata": {
        "id": "esoXaRjMEZXP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EuAUt7IAVFaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"ahmednasser1601\",\"key\":\"fd950b67a38861322900a50fdc9f6881\"}\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Y2tcs-BuVGIx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download diabetic-retinopathy-detection -f sample.zip\n",
        "!kaggle competitions download diabetic-retinopathy-detection -f sampleSubmission.csv.zip\n",
        "!kaggle competitions download diabetic-retinopathy-detection -f trainLabels.csv.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5R0J-qIUwh6",
        "outputId": "3efa09d3-0c4d-4462-9aa6-c8d0ee952b6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample.zip to /content\n",
            "\r  0% 0.00/10.4M [00:00<?, ?B/s]\r 96% 10.0M/10.4M [00:00<00:00, 103MB/s]\n",
            "100% 10.4M/10.4M [00:00<00:00, 105MB/s]\n",
            "Downloading sampleSubmission.csv.zip to /content\n",
            "  0% 0.00/81.6k [00:00<?, ?B/s]\n",
            "100% 81.6k/81.6k [00:00<00:00, 42.3MB/s]\n",
            "Downloading trainLabels.csv.zip to /content\n",
            "  0% 0.00/69.4k [00:00<?, ?B/s]\n",
            "100% 69.4k/69.4k [00:00<00:00, 28.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sample.zip\n",
        "!unzip sampleSubmission.csv.zip\n",
        "!unzip trainLabels.csv.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xclzYvZXG13",
        "outputId": "76f6a6e4-aa98-4254-a445-3129c360789f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sample.zip\n",
            "   creating: sample/\n",
            "  inflating: sample/10_left.jpeg     \n",
            "  inflating: sample/10_right.jpeg    \n",
            "  inflating: sample/13_left.jpeg     \n",
            "  inflating: sample/13_right.jpeg    \n",
            "  inflating: sample/15_left.jpeg     \n",
            "  inflating: sample/15_right.jpeg    \n",
            "  inflating: sample/16_left.jpeg     \n",
            "  inflating: sample/16_right.jpeg    \n",
            "  inflating: sample/17_left.jpeg     \n",
            "  inflating: sample/17_right.jpeg    \n",
            "Archive:  sampleSubmission.csv.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "Archive:  trainLabels.csv.zip\n",
            "  inflating: trainLabels.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm sample.zip\n",
        "!rm sampleSubmission.csv.zip\n",
        "!rm trainLabels.csv.zip\n"
      ],
      "metadata": {
        "id": "onphbk-FYCzd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zC3slyoVIISf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readTrainCsv():\n",
        "  raw_df = pd.read_csv('trainLabels.csv', sep=',')\n",
        "  print(type(raw_df)) #<class 'pandas.core.frame.DataFrame'>\n",
        "  row_count=raw_df.shape[0] #gives number of row count row_count=35126 \n",
        "  col_count=raw_df.shape[1] #gives number of col count col count=2\n",
        "  print(\"row_count=\"+str(row_count)+\" col count=\"+str(col_count))\n",
        "  raw_df[\"PatientID\"] = ''\n",
        "  header_list = list(raw_df.columns)\n",
        "  print(header_list) # ['image', 'level', 'PatientID']\n",
        "  # double check if level of left and right are same or not\n",
        "  ImageLevelHash = {}\n",
        "  patientIDList = []\n",
        "\n",
        "  for index, row in raw_df.iterrows():\n",
        "    # 0 is image, 1 is level, 2 is PatientID, 3 is data\n",
        "    key = row[0] + ''\n",
        "    patientID = row[0] + ''\n",
        "    patientID = patientID.replace('_right','')\n",
        "    patientID = patientID.replace('_left','')\n",
        "    #print(\"Adding patient ID\"+ patientID)\n",
        "    raw_df.at[index, 'PatientID'] = patientID\n",
        "    patientIDList.append(patientID)\n",
        "    ImageLevelHash[key] = str(row[1]) # level\n",
        "              \n",
        "  global uniquePatientIDList\n",
        "  uniquePatientIDList = sorted(set(patientIDList))\n",
        "  count=0;\n",
        "  for patientID in uniquePatientIDList:\n",
        "    left_level = ImageLevelHash[str(patientID+'_left')]\n",
        "    right_level = ImageLevelHash[str(patientID+'_right')]\n",
        "    #right_exists = str(patientID+'_right') in raw_df.values\n",
        "    if (left_level != right_level):\n",
        "      count = count+1\n",
        "      #print(\"Warning for patient=\"+ str(patientID) + \" left_level=\" + left_level+ \" right_level=\" +right_level)\n",
        "\n",
        "  print(\"count of images with both left and right eye level not matching=\"+str(count)) # 2240\n",
        "  print(\"number of unique patients=\"+str(len(uniquePatientIDList))) # 17563\n",
        "  return raw_df"
      ],
      "metadata": {
        "id": "-O-fkjPeaDjV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)\n",
        "print(\"Reading trainLabels.csv...\")\n",
        "df = readTrainCsv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ETbeAV6ax81",
        "outputId": "701b2401-8556-49e7-96ad-ffb5d386ade5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading trainLabels.csv...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "row_count=35126 col count=2\n",
            "['image', 'level', 'PatientID']\n",
            "count of images with both left and right eye level not matching=2240\n",
            "number of unique patients=17563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "  s = df.loc[df.index[i], 'PatientID'] # get patient id of patients\n",
        "  print(str(i) + \" patient's patientID=\"+str(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edrIQqVva8_O",
        "outputId": "6bfc1a59-2ad8-4f59-ae7c-e0bc3d13ba7f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 patient's patientID=10\n",
            "1 patient's patientID=10\n",
            "2 patient's patientID=13\n",
            "3 patient's patientID=13\n",
            "4 patient's patientID=15\n",
            "5 patient's patientID=15\n",
            "6 patient's patientID=16\n",
            "7 patient's patientID=16\n",
            "8 patient's patientID=17\n",
            "9 patient's patientID=17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df has 3 columns ['image', 'level', 'PatientID']\n",
        "keepImages =  list(ImageNameDataHash.keys())\n",
        "df = df[df['image'].isin(keepImages)]\n",
        "print(len(df)) # 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LmnHA5IbC66",
        "outputId": "41f53f0f-3f92-4bbe-9f43-f4777fdf9eed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert hash to dataframe\n",
        "imageNameArr = []\n",
        "dataArr = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  key = str(row[0])\n",
        "  if key in ImageNameDataHash:\n",
        "    imageNameArr.append(key)\n",
        "    dataArr.append(np.array(ImageNameDataHash[key])) # np.array\n",
        "\n",
        "df2 = pd.DataFrame({'image': imageNameArr, 'data': dataArr})\n",
        "df2_header_list = list(df2.columns) \n",
        "print(df2_header_list) # ['image', 'data']\n",
        "print(len(df2)) # 1000\n",
        "#print(df2.describe(include='all'))\n",
        "#print(df2.sample(3)) # 3 rows x 2 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmBZTDygbUVZ",
        "outputId": "67ae0ba3-8592-484c-a210-4d1f29db829e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['image', 'data']\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(df) != len(df2):\n",
        "  print(\"Error length of df != df2\")\n",
        "    \n",
        "for idx in range(0,len(df)):\n",
        "  if (df.loc[df.index[idx], 'image'] != df2.loc[df2.index[idx], 'image']):\n",
        "    print(\"Error \" + df.loc[df.index[idx], 'image'] +\"==\" + df2.loc[df2.index[idx], 'image'])\n",
        "        \n",
        "print(df2.dtypes)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNM2Agkdbbit",
        "outputId": "1756b2fa-307e-47b4-8da1-acca739614f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image    float64\n",
            "data     float64\n",
            "dtype: object\n",
            "image        object\n",
            "level         int64\n",
            "PatientID    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(df2, df, left_on='image', right_on='image', how='outer')\n",
        "df_header_list = list(df.columns) \n",
        "print(df_header_list) # 'image', 'data', level', 'PatientID'\n",
        "print(len(df)) # 1000\n",
        "print(df.sample())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "RxBukIzGbjIz",
        "outputId": "3d8cd013-1802-47e4-a113-c90e2d13edf3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ab117b3776d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_header_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_header_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 'image', 'data', level', 'PatientID'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 ):\n\u001b[0;32m-> 1256\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat"
          ]
        }
      ]
    }
  ]
}